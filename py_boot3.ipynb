{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "699a6403-0cb7-423b-93b4-370f104b1a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchain\n",
      "Version: 0.3.26\n",
      "Summary: Building applications with LLMs through composability\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: C:\\Users\\thota\\gen_ai\\genai\\Lib\\site-packages\n",
      "Requires: langchain-core, langchain-text-splitters, langsmith, pydantic, PyYAML, requests, SQLAlchemy\n",
      "Required-by: langchain-community\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9df52361-5210-4645-b7d4-899c54781d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "load_dotenv(find_dotenv(),override=True)\n",
    "\n",
    "def load_doc(file):\n",
    "    import os\n",
    "    from langchain.document_loaders import PyPDFLoader\n",
    "    name,extension=os.path.splitext(file)\n",
    "\n",
    "    if extension=='.pdf':\n",
    "        loader=PyPDFLoader(file)\n",
    "    elif extension=='.docx':\n",
    "        from langchain.document_loaders import Docx2txtLoader\n",
    "        loader=Docx2txtLoader(file)\n",
    "    else:\n",
    "        print('document format not supported')\n",
    "        return None\n",
    "    \n",
    "    data=loader.load()\n",
    "    return data\n",
    "\n",
    "def load_from_wiki(query,lang='en',load_max_docs=2):\n",
    "    from langchain.document_loaders import WikipediaLoader\n",
    "    loader=WikipediaLoader(query=query,lang=lang,load_max_docs=load_max_docs)\n",
    "    data=loader.load()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e15fcff-d03b-4874-9435-fc89e47c61b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=load_doc(r\"C:\\Users\\thota\\Downloads\\WINSEMFRE2024-25_CHY1009_ETH_AP2024255000612_2025-04-19_Reference-Material-I.pdf\")\n",
    "def chunk_data(data,chunk_size=256):\n",
    "    from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "    text_splitter=RecursiveCharacterTextSplitter(chunk_size=chunk_size,chunk_overlap=0)\n",
    "    chunks=text_splitter.split_documents(data)\n",
    "    return chunks\n",
    "chunks=chunk_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39e47c4b-de18-48c2-b3f7-d15b271123f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import find_dotenv,load_dotenv\n",
    "load_dotenv(find_dotenv(),override=True)\n",
    "def insert_or_fetch_embeddings(index_name,chunks):\n",
    "    import pinecone \n",
    "    from langchain_community.vectorstores import Pinecone\n",
    "    from langchain_openai import OpenAIEmbeddings\n",
    "    from pinecone import ServerlessSpec\n",
    "    \n",
    "    pc=pinecone.Pinecone()\n",
    "    embeddings=OpenAIEmbeddings(model='text-embedding-3-small',dimensions=1536)\n",
    "    \n",
    "    if index_name in pc.list_indexes().names():\n",
    "        print(f'index {index_name} alredy exists!')\n",
    "        vector_store=Pinecone.from_existing_index(index_name,embeddings)\n",
    "        print('ok')\n",
    "    else:\n",
    "        print(f'creating {index_name} index...')\n",
    "        pc.create_index(\n",
    "            name=index_name,\n",
    "            dimension=1536,\n",
    "            metric='cosine',\n",
    "            spec=ServerlessSpec(\n",
    "                cloud=\"aws\",\n",
    "                region='us-east-1'\n",
    "            )\n",
    "        )\n",
    "        vector_store=Pinecone.from_documents(chunks,embeddings,index_name=index_name)\n",
    "        print('index created')\n",
    "    return vector_store\n",
    "\n",
    "def del_pinecone_index(index_name='all'):\n",
    "    import pinecone\n",
    "    pc=pinecone.Pinecone()\n",
    "    if index_name=='all':\n",
    "        indexes=pc.list_indexes().names()\n",
    "        for index in indexes:\n",
    "            pc.delete_index(index)\n",
    "        print('deleted!')\n",
    "    else:\n",
    "        pc.delete_index(index_name)\n",
    "        print(f'deleted {index_name}!')\n",
    "# del_pinecone_index('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f405570a-bef4-498d-b5be-7f4a756648bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q pinecone==5.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "106841be-d001-4860-b852-99e1ff93e02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index askadocument alredy exists!\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "index_name='askadocument'\n",
    "vector_store=insert_or_fetch_embeddings(index_name,chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "348b7e9b-2a28-4aca-9865-7f8c35a6d231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158\n"
     ]
    }
   ],
   "source": [
    "print(len(chunks))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96b3231-ba50-4ecc-97c4-31e1a7644c2b",
   "metadata": {},
   "source": [
    "## Asking questions from doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543d31ba-8d27-44a1-b547-64b05681f15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_and_get_ans(vector_store,q):\n",
    "    from langchain.chains import RetrievalQA\n",
    "    from langchain_openai import ChatOpenAI\n",
    "\n",
    "    llm=ChatOpenAI(model='gpt-4o',temperature=1)\n",
    "    retriever=vector_store.as_retriever(search_type='similarity',search_kwargs={'k':5})\n",
    "    chain=RetrievalQA.from_chain_type(llm=llm,chain_type='stuff',retriever=retriever)\n",
    "\n",
    "    answer=chain.invoke(q)\n",
    "    return answer\n",
    "answer=ask_and_get_ans(vector_store,'what is whole pdf about?')\n",
    "print(answer['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5834546-66ba-4832-98e3-01b019863162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Question 1:  hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Hello! How can I assist you today?\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Question 2:  what is in the 10 th page of this doc in short\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: I'm sorry, but I don't have access to the content of the 10th page of the document you're referring to.\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Question 3:  summary of this whole content\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: The content refers to several related points: \n",
      "\n",
      "1. It mentions two problems labeled \"Problem 1\" and \"Problem 2\" without further details.\n",
      "2. It provides an explanation of polymers, stating that the term \"polymer\" comes from Greek words meaning \"many parts\" and describes a polymer as a long-chain molecule composed of repeating units.\n",
      "3. It describes a specific type of polymer, Acrylonitrile-Butadiene-Styrene (ABS), which is a large molecule consisting mainly of polybutadiene chains with styrene-acrylonitrile copolymer branches.\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Question 4:  exit\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "i=1\n",
    "while True:\n",
    "    q=input(f'Question {i}: ')\n",
    "    i+=1\n",
    "    if q.lower() in ['quit','exit']:\n",
    "        time.sleep(2)\n",
    "        break\n",
    "    ans=ask_and_get_ans(vector_store,q)\n",
    "    print(f'Answer: {ans['result']}')\n",
    "    print('*'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4e01dbfa-2dc6-4187-83eb-3a2cbf2ffc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating chatgpt index...\n",
      "index created\n"
     ]
    }
   ],
   "source": [
    "data1=load_from_wiki('ChatGPT')\n",
    "chunks=chunk_data(data1)\n",
    "index_name='chatgpt'\n",
    "vector_store=insert_or_fetch_embeddings(index_name,chunks)\n",
    "# del_pinecone_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d534479-252d-4c58-890d-c65d5a728d03",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ask_and_get_ans' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m anwer=\u001b[43mask_and_get_ans\u001b[49m(vector_store,\u001b[33m'\u001b[39m\u001b[33mall important words according to you from this content\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(anwer[\u001b[33m'\u001b[39m\u001b[33mresult\u001b[39m\u001b[33m'\u001b[39m]) \n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# print(data1)\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'ask_and_get_ans' is not defined"
     ]
    }
   ],
   "source": [
    "anwer=ask_and_get_ans(vector_store,'all important words according to you from this content')\n",
    "print(anwer['result']) \n",
    "# print(data1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db13725e-4795-4097-80be-c7f4b7277055",
   "metadata": {},
   "source": [
    "## Using chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09e30147-733a-40d3-a6f9-085b25bfc4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "afeec336-07ce-46fe-9981-db6019a211dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embdng_chroma(chunks,persist_directory='./chroma_db'):\n",
    "    from langchain.vectorstores import Chroma\n",
    "    from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "    embeddings=OpenAIEmbeddings(model='text-embedding-3-small',dimensions=1536)\n",
    "    vector_store=Chroma.from_documents(chunks,embeddings,persist_directory=persist_directory)\n",
    "    return vector_store\n",
    "\n",
    "def load_embeddings_chroma(persist_directory='./chroma_db'):\n",
    "    from langchain.vectorstores import Chroma\n",
    "    from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "    embeddings=OpenAIEmbeddings(model='text-embedding-3-small',dimensions=1536)\n",
    "    vector_store=Chroma(persist_directory=persist_directory,embedding_function=embeddings)\n",
    "    return vector_store\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81652d8-9088-488c-9d3f-a8e14ebad365",
   "metadata": {},
   "source": [
    "data1=load_doc(r\"C:\\Users\\thota\\Downloads\\OnePlus_5_User_Manual.pdf\")\n",
    "chunks=chunk_data(data1)\n",
    "vector_store=create_embdng_chroma(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e79207ac-382c-449a-9ceb-efc22db7c806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some safety precautions you should follow:\n",
      "\n",
      "1. Do not switch on the device when prohibited or when it may cause interference or danger.\n",
      "2. When operating a vehicle, prioritize safety and obey related regulations in the area or country you are driving in.\n",
      "3. Do not store or carry your mobile phone or accessories near liquid or flammable gas and avoid placing them near safety air bags.\n",
      "4. Avoid using the phone if the antenna is damaged, as it may cause injury.\n",
      "\n",
      "Following these guidelines will help prevent injury to your device, property, yourself, or others.\n"
     ]
    }
   ],
   "source": [
    "q='safety precautions?'\n",
    "ans=ask_and_get_ans(vector_store,q)\n",
    "print(ans['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66b77d66-85a0-4c24-b434-43b93e9837c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thota\\AppData\\Local\\Temp\\ipykernel_7388\\671103975.py:14: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vector_store=Chroma(persist_directory=persist_directory,embedding_function=embeddings)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ask_and_get_ans' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m db=load_embeddings_chroma()\n\u001b[32m      2\u001b[39m q=\u001b[33m'\u001b[39m\u001b[33mmain points?\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m ans=\u001b[43mask_and_get_ans\u001b[49m(vector_store,q)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(ans[\u001b[33m'\u001b[39m\u001b[33mresult\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[31mNameError\u001b[39m: name 'ask_and_get_ans' is not defined"
     ]
    }
   ],
   "source": [
    "db=load_embeddings_chroma()\n",
    "q='main points?'\n",
    "ans=ask_and_get_ans(vector_store,q)\n",
    "print(ans['result'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc011dfe-733e-429d-ae81-4fa9ed234c55",
   "metadata": {},
   "source": [
    "## Adding Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "548939b2-8d7b-4900-859b-78d2090ac7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thota\\AppData\\Local\\Temp\\ipykernel_14520\\3552496561.py:9: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory=ConversationBufferMemory(memory_key='chat_history',return_messages=True)\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "import os\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "load_dotenv(find_dotenv(),override=True)\n",
    "llm=ChatOpenAI(model_name='gpt-4-turbo-preview',temperature=0)\n",
    "retriever=vector_store.as_retriever(search_type='similarity',search_kwargs={'k':5})\n",
    "memory=ConversationBufferMemory(memory_key='chat_history',return_messages=True)\n",
    "crc=ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory,\n",
    "    chain_type='stuff',\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6730bb3-8e1c-4cb2-a672-d3824a3f284b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question(q,chain):\n",
    "    result=chain.invoke({'question':q})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74d98150-c4bf-469e-bff7-932cf151f3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following pieces of context to answer the user's question. \n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "----------------\n",
      "How many pendant are in this polymer?\n",
      "Pendant means side chain\n",
      "\n",
      "Module 4: Polymer\n",
      "• The word polymer is \n",
      "derived from the classical \n",
      "Greek words poly meaning \n",
      "“many” and meres \n",
      "meaning “parts.” \n",
      "• Simply stated, a polymer is \n",
      "a long-chain molecule that \n",
      "is composed of a large \n",
      "number of repeating units\n",
      "\n",
      "PolydispersityIndex (PDI)\n",
      "• Which one of the following has high polydispersity\n",
      "index?\n",
      "16\n",
      "\n",
      "General Trends of Tg\n",
      "Tg\n",
      " Strength of intermolecular force (or appropriately interchain force)\n",
      "Tg\n",
      " Degree of crystallinity \n",
      "Tg\n",
      " Degree of cross-linking \n",
      "Tg\n",
      "Flexibility of a polymer main chain and branches \n",
      "1\n",
      "Tg\n",
      "\n",
      "It is  a giant molecule predominantly made up of chains of polybutadiene backbone with \n",
      "styrene-acrylonitrile copolymer (SAN) branches. \n",
      "Acrylonitrile-Butadiene-Styrene (ABS)\n",
      "Human: How many subtopics are in it?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "q='How many subtopics are in it?'\n",
    "result1=ask_question(q,crc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a0f1567-2ec0-41b9-982a-8c39e8c73b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "\n",
      "Human: How many subtopics are in it?\n",
      "Assistant: Based on the provided text, there are 34 subtopics listed under \"What’s in The Box?\" section.\n",
      "Human: How many subtopics are in it?\n",
      "Assistant: There is 1 subtopic listed under the \"What’s in The Box?\" section.\n",
      "Human: How many subtopics are in it?\n",
      "Assistant: There is 1 subtopic listed under the \"What’s in The Box?\" section.\n",
      "Human: How many subtopics are in it?\n",
      "Assistant: There is only one subtopic listed under the \"What’s in The Box?\" section.\n",
      "Follow Up Input: what is main content in that?\n",
      "Standalone question:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following pieces of context to answer the user's question. \n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "----------------\n",
      "|       What’s in the Box              Device              OxygenOS              Safety Information\n",
      "\n",
      "|       What’s in the Box              Device              OxygenOS              Safety Information\n",
      "\n",
      "|       What’s in the Box              Device              OxygenOS              Safety Information\n",
      "\n",
      "|       What’s in the Box              Device              OxygenOS              Safety Information\n",
      "\n",
      "|       What’s in the Box              Device              OxygenOS              Safety Information\n",
      "Human: What is the main content of the subtopic listed under the \"What’s in The Box?\" section?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The main content under the \"What’s in the Box?\" section typically lists the items included with the purchase of the device. This usually covers the device itself, a charging cable, a power adapter, any included earphones or case, and sometimes a tool for ejecting the SIM card tray. The exact contents can vary depending on the device model and manufacturer.\n"
     ]
    }
   ],
   "source": [
    "q='what is main content in that?'\n",
    "result=ask_question(q,crc)\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c726190-e644-4669-b2f8-f3a425694612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, there are four subtopics within the module on polymers. These are:\n",
      "\n",
      "1. Definition of a polymer.\n",
      "2. Polydispersity Index (PDI).\n",
      "3. General Trends of Tg (Glass Transition Temperature).\n",
      "4. Description of Acrylonitrile-Butadiene-Styrene (ABS) as a specific example of a polymer.\n"
     ]
    }
   ],
   "source": [
    "print(result1['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f648b413-7c2f-4fe2-b4cf-6e99fa518dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='How many subtopics are in it?' additional_kwargs={} response_metadata={}\n",
      "content='Based on the provided context, there are four subtopics within the module on polymers. These are:\\n\\n1. Definition of a polymer.\\n2. Polydispersity Index (PDI).\\n3. General Trends of Tg (Glass Transition Temperature).\\n4. Description of Acrylonitrile-Butadiene-Styrene (ABS) as a specific example of a polymer.' additional_kwargs={} response_metadata={}\n"
     ]
    }
   ],
   "source": [
    "for item in result1['chat_history']:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd90d044-7070-4168-ba98-427cff9901ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T15:30:28.417579Z",
     "start_time": "2025-07-30T15:30:26.335892Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thota\\AppData\\Local\\Temp\\ipykernel_14520\\671103975.py:14: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vector_store=Chroma(persist_directory=persist_directory,embedding_function=embeddings)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "Use the following pieces of context to answer user's question.\n",
      "---------------------\n",
      "Context:```Monomers\n",
      "Monomers: These are simple molecules, which combine with \n",
      "each other to form polymers. Monomers are also called \n",
      "“building blocks” of polymers. \n",
      "For example, ethylene, methylmethacrylate,  vinyl chloride, \n",
      "etc.\n",
      "\n",
      "• The monomer is the repeat unit of the polymer, and a \n",
      "typical polymer may have from hundreds to hundreds \n",
      "of thousands of repeat units. \n",
      "• Synthetic polymers are created by chemical reactions \n",
      "in the laboratory; natural polymers (or biopolymers)\n",
      "\n",
      "2. In simple addition polymerization, n-monomers are added together to \n",
      "form a polymer chain with n-repeat units, n is very large 100s or 1000s\n",
      "Monomer Polymer\n",
      "(PMMA) \n",
      "Salient Features of Polymerization Reaction:\n",
      "\n",
      "Conducting polymer structures\n",
      "Polymers with alternating double bonds can conduct electricity, \n",
      "hence called conducting polymers\n",
      "Examples for conducting polymers\n",
      "monomers polymer\n",
      "\n",
      "Module 4: Polymer\n",
      "• The word polymer is \n",
      "derived from the classical \n",
      "Greek words poly meaning \n",
      "“many” and meres \n",
      "meaning “parts.” \n",
      "• Simply stated, a polymer is \n",
      "a long-chain molecule that \n",
      "is composed of a large \n",
      "number of repeating units```\n",
      "\n",
      "Human: \n",
      "Question:```Main examples of the monomers```\n",
      "Chat History: ``````\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'question': 'Main examples of the monomers', 'chat_history': [HumanMessage(content='Main examples of the monomers', additional_kwargs={}, response_metadata={}), AIMessage(content='The main examples of monomers mentioned are:\\n\\n- Ethylene\\n- Methyl methacrylate\\n- Vinyl chloride', additional_kwargs={}, response_metadata={})], 'answer': 'The main examples of monomers mentioned are:\\n\\n- Ethylene\\n- Methyl methacrylate\\n- Vinyl chloride'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "import os\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "load_dotenv(find_dotenv(),override=True)\n",
    "llm=ChatOpenAI(model_name='gpt-4-turbo-preview',temperature=0)\n",
    "retriever=vector_store.as_retriever(search_type='similarity',search_kwargs={'k':5})\n",
    "memory=ConversationBufferMemory(memory_key='chat_history',return_messages=True)\n",
    "system_template=r'''\n",
    "Use the following pieces of context to answer user's question.\n",
    "---------------------\n",
    "Context:```{context}```\n",
    "'''\n",
    "\n",
    "user_template='''\n",
    "Question:```{question}```\n",
    "Chat History: ```{chat_history}```\n",
    "'''\n",
    "\n",
    "messages=[\n",
    "    SystemMessagePromptTemplate.from_template(system_template),\n",
    "    HumanMessagePromptTemplate.from_template(user_template)\n",
    "]\n",
    "\n",
    "qa_prompt=ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "\n",
    "crc=ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory,\n",
    "    chain_type='stuff',\n",
    "    combine_docs_chain_kwargs={'prompt':qa_prompt},\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "db=load_embeddings_chroma()\n",
    "q='Main examples of the monomers'\n",
    "result=ask_question(q,crc)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2eaa703093626a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The main examples of monomers mentioned are:\n",
      "\n",
      "- Ethylene\n",
      "- Methyl methacrylate\n",
      "- Vinyl chloride\n"
     ]
    }
   ],
   "source": [
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbf74e8-cd69-4824-8603-b6e525251fe9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
